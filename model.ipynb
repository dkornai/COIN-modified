{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np; np.set_printoptions(linewidth = 150, suppress=True)\n",
    "from copy import deepcopy\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate import generate_TPM, generate_contexts_cues\n",
    "from particle import Particle, resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global context probabilities:\n",
      "[0.53071743 0.04051346 0.21692036 0.21184875]\n",
      "True context transition probability matrix:\n",
      "[[0.86239456 0.10909311 0.02850528 0.00000705]\n",
      " [0.11357978 0.33306852 0.33658356 0.21676815]\n",
      " [0.08137829 0.         0.75657932 0.1620424 ]\n",
      " [0.23946346 0.         0.00004106 0.76049548]]\n",
      "Element 0: Frequency 466\n",
      "Element 1: Frequency 105\n",
      "Element 2: Frequency 187\n",
      "Element 3: Frequency 242\n"
     ]
    }
   ],
   "source": [
    "# Test the function with example parameters\n",
    "input_dim = 6\n",
    "\n",
    "n_contexts_init = 4\n",
    "\n",
    "h_gamma_c = 1.0\n",
    "h_alpha_c = 5.0\n",
    "h_kappa_c = 2.0\n",
    "\n",
    "true_TPM = generate_TPM(input_dim, n_contexts_init, h_gamma_c, h_alpha_c, h_kappa_c)\n",
    "\n",
    "true_CEM = [\n",
    "    [1, 1, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 1, 1],\n",
    "    [0, 0, 1, 1, 0, 0],\n",
    "    [1, 0, 0, 0, 0, 1]\n",
    "]\n",
    "\n",
    "true_CEM = np.array(true_CEM, dtype = np.int64)\n",
    "\n",
    "t_steps = 1000\n",
    "contexts, cues = generate_contexts_cues(true_TPM, true_CEM, t_steps)\n",
    "\n",
    "\n",
    "# Print the context frequencies in the generated data\n",
    "unique_elements, counts = np.unique(contexts, return_counts=True)\n",
    "element_frequency = dict(zip(unique_elements, counts))\n",
    "for element, frequency in element_frequency.items():\n",
    "    print(f\"Element {element}: Frequency {frequency}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> processing cue 999 of 1000     \r"
     ]
    }
   ],
   "source": [
    "# Specify the hyperparameters\n",
    "model_hyperparam = {\n",
    "    'h_gamma_c' : h_gamma_c,\n",
    "    'h_alpha_c' : h_alpha_c,\n",
    "    'h_kappa_c' : h_kappa_c\n",
    "    }\n",
    "\n",
    "# Set up the ensemble of particles\n",
    "particles = [Particle(input_dim=input_dim, n_contexts_init=0, hyperparam=model_hyperparam) for _ in range(20)]\n",
    "\n",
    "# Learn using data\n",
    "for i, cue in enumerate(cues):\n",
    "    print(f'>> processing cue {i} of {len(cues)}     ', end = '\\r')    \n",
    "    \n",
    "    # Calculate the responsibility, and use this to resample the particles\n",
    "    weights = []\n",
    "    for particle in particles:\n",
    "        particle.calculate_joint(cue)\n",
    "        particle.calculate_responsibility()\n",
    "        weights.append(particle.get_responsibility())\n",
    "    \n",
    "    particles = resample(particles, weights)\n",
    "    \n",
    "    # Propagate the context and sufficient statistics\n",
    "    for particle in particles:\n",
    "        particle.propagate_context()\n",
    "        particle.propagate_sufficient_statistics(cue)\n",
    "\n",
    "    # Sample the parameters to generate diversity\n",
    "    for particle in particles:\n",
    "        particle.sample_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_CEM:\n",
      "[[1 1 0 0 0 0]\n",
      " [0 0 0 0 1 1]\n",
      " [0 0 1 1 0 0]\n",
      " [1 0 0 0 0 1]]\n",
      "Estimated CEM:\n",
      "[[1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 1. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 1.]]\n",
      "True TPM:\n",
      "[[0.86 0.11 0.03 0.  ]\n",
      " [0.11 0.33 0.34 0.22]\n",
      " [0.08 0.   0.76 0.16]\n",
      " [0.24 0.   0.   0.76]]\n",
      "Estimated TPM:\n",
      "[[0.81 0.15 0.04 0.  ]\n",
      " [0.12 0.34 0.36 0.15]\n",
      " [0.08 0.01 0.7  0.2 ]\n",
      " [0.23 0.   0.   0.75]]\n"
     ]
    }
   ],
   "source": [
    "# Estimate the CEM \n",
    "list_cue_emission_matrix = np.array([particle.get_cue_emission_matrix() for particle in particles])\n",
    "estimated_CEM = np.round(np.average(list_cue_emission_matrix, axis = 0), 1)\n",
    "\n",
    "# Use the similarity between rows of the estimated and true CEM to reorder rows in the output data\n",
    "distance_matrix = cdist(true_CEM, estimated_CEM, 'euclidean')\n",
    "closest_indices = np.argmin(distance_matrix, axis=1)\n",
    "\n",
    "# Compare the estimate and the true CEM\n",
    "print(\"true_CEM:\")\n",
    "print(true_CEM)\n",
    "print(\"Estimated CEM:\")\n",
    "print(estimated_CEM[closest_indices])\n",
    "\n",
    "# Estimate the TPM\n",
    "n_contexts_inferred = len(particles[0].get_context_counts())\n",
    "exp_TPM = np.zeros((n_contexts_inferred, n_contexts_inferred))\n",
    "for j in range(n_contexts_inferred):\n",
    "    for k in range(n_contexts_inferred):\n",
    "        for particle in particles:\n",
    "            exp_TPM[j,k] += (h_alpha_c*particle.get_global_context_prob()[k] + h_kappa_c*(j == k) + particle.get_transition_counts()[j,k])/(h_alpha_c+h_kappa_c+particle.get_context_counts()[j])\n",
    "exp_TPM /= len(particles)\n",
    "\n",
    "# Compare the estimated and the true TPM\n",
    "print(\"True TPM:\")\n",
    "print(np.round(true_TPM, 2))\n",
    "print(\"Estimated TPM:\")\n",
    "print(np.round(exp_TPM[closest_indices][:,closest_indices], 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
